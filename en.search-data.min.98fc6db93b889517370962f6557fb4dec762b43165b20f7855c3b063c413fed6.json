[{"id":0,"href":"/showcase/docs/Talleres/Actividades/","title":"Actividades","section":"Talleres","content":" Actividades # En este espacio se mostraran algunas de las actividades desarrolladas en clase.\nSolidos Platonicos S√≥lidos Plat√≥nicos # Con el proposito de familiarizarse con el uso de la plantilla y P5.js, se implementa el s√≥lido plat√≥nico Octaedro, logrando el siguiente resultado. "},{"id":1,"href":"/showcase/docs/Talleres/Actividades/Solidos_Platonicos/","title":"Solidos Platonicos","section":"Actividades","content":" S√≥lidos Plat√≥nicos # Con el proposito de familiarizarse con el uso de la plantilla y P5.js, se implementa el s√≥lido plat√≥nico Octaedro, logrando el siguiente resultado.\n"},{"id":2,"href":"/showcase/docs/Talleres/Ilusiones/","title":"Ilusiones","section":"Talleres","content":" Ilusiones visuales # El desarrollo de este taller tiene como objetivo implementar la ilusion visual \u0026ldquo;Stepping Feet\u0026rdquo; e implementar una aplicaci√≥n visual de procesamiento de im√°genes en un software que tenga diferentes n√∫cleos de im√°genes y visualizaci√≥n de histogramas de im√°genes.\nEl desarrollo del taller corresponde a los temas:\nFenomenos visuales e ilusiones opticas Masking Masking Masking - Image Kernel # Introducci√≥n # Image Processing o procesamiento digital de imagenes, es el producto de utilizar un kernel, matriz de convolucion o mascara, para el desenfoque, enfoque, realce, detecci√≥n de bordes, entre otros. Contexto # El proceso de aplicar una mascara sobre una imagen, consta en modificar el valor de cada pixel de la imagen, tomando informacion de los pixeles que la rodean, dependiendo del kernel se da prioridad a ciertos pixeles sobre otro, se pueden lograr efectos diferentes sobre la imagen modificando el kernel. Stepping Feet \u0026ldquo;Stepping Feet\u0026rdquo; Motion Illusion # Introducci√≥n # Stepping Feet o ilusion de los pies escalonadoes es un fenomeno de percepcion de movimiento en el cual se observa el movimiento de dos bloques un azul y otro amarillo. Los bloques parecen caminar alternativamente. El movimiento es m√°s pronunciado si no se miran directamente los bloques, sino entre ellos. Aunque parecen ser pies dando pasos, en realidad su movimiento es siempre simult√°neo. "},{"id":3,"href":"/showcase/docs/Talleres/Ilusiones/Masking/","title":"Masking","section":"Ilusiones","content":" Masking - Image Kernel # Introducci√≥n # Image Processing o procesamiento digital de imagenes, es el producto de utilizar un kernel, matriz de convolucion o mascara, para el desenfoque, enfoque, realce, detecci√≥n de bordes, entre otros.\nContexto # El proceso de aplicar una mascara sobre una imagen, consta en modificar el valor de cada pixel de la imagen, tomando informacion de los pixeles que la rodean, dependiendo del kernel se da prioridad a ciertos pixeles sobre otro, se pueden lograr efectos diferentes sobre la imagen modificando el kernel.\nResultados y C√≥digo (Soluci√≥n) # Image Processing - Instrucciones Instrucciones de uso\nPresione la tecla \u0026lsquo;c\u0026rsquo; para intercambiar entre la imagen original y la modificada. Presione la tecla \u0026lsquo;i\u0026rsquo; para intercambiar entre la vista de configuracion y la vista de visualizacion de la imagen Presione la tecla \u0026rsquo;s\u0026rsquo; para redimensionar la imagen Discusi√≥n # Diferentes resultados se obtienen con diferentes kernels. Dependiendo de la imagen se pueden obtener mejores resultados. Conclusiones # El campo de Image Processing tiene varias aplicaciones, una de las mas conocidas es utilizando un kernel Gaussian, el cual difumina la imagen original.\nReferencias # Wikipedia. Kernel (image processing). https://en.wikipedia.org/wiki/Kernel_%28image_processing%29\nJean Pierre Charalambos. p5.quadrille.js. https://objetos.github.io/p5.quadrille.js/\n"},{"id":4,"href":"/showcase/docs/Talleres/Ilusiones/Stepping_Feet/","title":"Stepping Feet","section":"Ilusiones","content":" \u0026ldquo;Stepping Feet\u0026rdquo; Motion Illusion # Introducci√≥n # Stepping Feet o ilusion de los pies escalonadoes es un fenomeno de percepcion de movimiento en el cual se observa el movimiento de dos bloques un azul y otro amarillo. Los bloques parecen caminar alternativamente. El movimiento es m√°s pronunciado si no se miran directamente los bloques, sino entre ellos. Aunque parecen ser pies dando pasos, en realidad su movimiento es siempre simult√°neo.\nContexto # Stuart Anstis demostr√≥ por primera vez esta ilusi√≥n en 2003.\nEn la ilusi√≥n cuando el bloque azul se encuentra sobre las franjas blancas, el contraste es alto (azul oscuro frente a blanco) y f√°cilmente visible, por lo que parece moverse m√°s r√°pido que su velocidad real. Por el contrario, cuando el bloque azul est√° contra las franjas negras, el contraste es bajo (azul oscuro vs. negro) y m√°s dif√≠cil de ver, por lo que el movimiento parece m√°s lento. Los efectos opuestos ocurren para el bloque amarillo.\nResultados y C√≥digo (Soluci√≥n) # Presione la tecla \u0026lsquo;0\u0026rsquo; para quitar la textura. Mueva la barra deslizante para aumentar o disminuir la velocidad. stepping-feet let x = 0; let xspeed = 1; let slider; let flag = true; let val; function setup() { createCanvas(710, 310); noStroke(); slider = createSlider(0, 3, 1, 0.5); slider.position(5, 320); } function draw() { background(0); val = slider.value(); if (flag) { xspeed = val; } else { xspeed = -val; } // Quitar la textura if (keyIsPressed \u0026amp;\u0026amp; key == \u0026#39;0\u0026#39;) { background(150); } else { createBars(); } moveBrick(); } // Funci√≥n para crear las franjas verticales blancas function createBars() { let len = 12; for (let i = 0; i \u0026lt; width / len; i++) { fill(255); if (i % 2 == 0) rect(i * len, height, len, -height); } } // Funcion para mover los bloques function moveBrick() { fill(0, 0, 255); rect(x, 100, 70, 30); fill(255, 255, 0); rect(x, 200, 70, 30); if (x + 70 \u0026gt;= width) { flag = false; } else if (x \u0026lt;= 0) { flag = true; } x += xspeed; } Discusi√≥n # En general, los movimientos de mayor contraste se ven m√°s r√°pidos que los de menor contraste. El efecto desaparece cuando se quita la textura ya que no queda contraste, mostrando c√≥mo el fondo de un objeto puede tener un efecto significativo en su velocidad percibida. Conclusiones # Al trabajar en esta ilusion se logra estudiar el efecto contraste, el cual es la tendencia a√±adir o reducir el valor de los objetos que percibimos al compararlos con otro objeto. Evidenciando que el contraste no solo modifica la latencia para esta ilusi√≥n, sino tambi√©n la amplitud del movimiento percibido.\nReferencias # Bach, M. (s. f.). ‚ÄúStepping feet‚Äù Motion Illusion. 148 Visual Phenomena \u0026amp; Optical Illusions. https://michaelbach.de/ot/mot-feetLin/\nAnstis, S (2003). \u0026ldquo;Moving Objects Appear to Slow Down at Low Contrasts\u0026rdquo;. Neural Networks. 16 (5): 933‚Äì938. doi:10.1016/S0893-6080(03)00111-4.\nWikipedia. Stepping feet illusion. https://en.wikipedia.org/wiki/Stepping_feet_illusion, Contrast effect https://en.wikipedia.org/wiki/Contrast_effect\n"},{"id":5,"href":"/showcase/docs/Talleres/Rendering/Anti-aliasing/","title":"Anti Aliasing","section":"Rendering","content":" Anti-aliasing # Introducci√≥n # Con el siguinte taller se busca revisar los conceptos de coordenadas baricentricas, rasterizaci√≥n y aliasing al realizar una implementaci√≥n del suavizado o antiescalinamiento(anti-aliasing) en p5.\nContexto # El antialiasing es una t√©cnica utilizada en gr√°ficos por computadora para eliminar el efecto de aliasing. Este efecto consiste en la aparici√≥n de bordes irregulares o \u0026ldquo;jaggies\u0026rdquo; en una imagen rasterizada (una imagen renderizada usando p√≠xeles). El problema de los bordes irregulares t√©cnicamente ocurre debido a la distorsi√≥n de la imagen cuando la conversi√≥n del escaneo se realiza con muestreo a baja frecuencia, el cual resulta en la p√©rdida de informaci√≥n de la imagen.\nEl proceso de antialiasing determina qu√© color debemos usar cuando rellenamos p√≠xeles. Como se puede observar en la siguente imagen, cuando el antialiasing est√° habilitado, los p√≠xeles son tonos de gris, sin embargo, cuando se deshabilita, el p√≠xel se rellena como negro o blanco s√≥lido y la forma se ve irregular.\nMuestreo m√∫ltiple Antialiasing (MSAA - Multisampling) # Existen diferente metodos para hacer que la imagen sea m√°s agradable para el usuario, entre ellos se encuentra el MSAA - Multisampling, este metodo es uno de los m√°s basicos sin embargo es uno de los m√°s usados en juegos de rango medio, ya que tiene un equilibrio entre rendimiento y calidad.\nEl antialiasing MSAA se realiza siguiendo los siguientes pasos:\nSe toma una imagen que tiene jaggies. La imagen se representa en su estructura de alta resoluci√≥n. A alta resoluci√≥n, se toman muestras de color de p√≠xeles adicionales que estaban ausentes en la imagen de baja resoluci√≥n. A baja resoluci√≥n, cada p√≠xel obtiene otro color al que se ha llegado a un promedio de p√≠xeles adicionales. El nuevo color ayuda a que los p√≠xeles se mezclen de manera m√°s efectiva y los jaggies resultan ser menos notables. Para entrar en m√°s detalle de como funciona este m√©todo primero se deben entender el concepto de rasterizaci√≥n el cual toma todos los v√©rtices que pertenecen a una objeto y los transforma en un conjunto de fragmentos. Para la implementaci√≥n realizada en este taller se hace uso del calculo de coordenadas baricentricas.\nA continuaci√≥n se muestra una cuadr√≠cula de p√≠xeles de pantalla, donde el centro de cada p√≠xel contiene un punto de muestreo que se utiliza para determinar si un p√≠xel est√° cubierto o no por el tri√°ngulo. Los puntos de muestra rojos indican que est√°n cubiertos por el tri√°ngulo y para ellos se generia un fragmento, dando como resultado una imagen con bordes irregulares.\nAl hacer uso del m√©todo MSAA, este no usa un √∫nico punto de muestreo para determinar la cobertura del tri√°ngulo, sino m√∫ltiples puntos de muestreo. Por ejemplo en la siguinete imagen se tienen 4 submuestras en un patr√≥n general y estos se utilizan para determinar la cobertura de los p√≠xeles. El lado izquierdo de la imagen se muestra c√≥mo determinar√≠amos normalmente la cobertura de un tri√°ngulo. Este p√≠xel espec√≠fico no ejecutar√° un sombreador de fragmentos (y, por lo tanto, permanecer√° en blanco) ya que su punto de muestra no estaba cubierto por el tri√°ngulo. El lado derecho de la imagen muestra una versi√≥n multimuestreada donde cada p√≠xel contiene 4 puntos de muestra. Aqu√≠ podemos ver que solo 2 puntos de muestra cubren el tri√°ngulo por lo que obtine un tono del color original, para detemimar el tono a usar en ese pixel se promedian los colores de cada submuestra por p√≠xel.\nEn general el MSAA utiliza un b√∫fer de profundidad/plantilla m√°s grande para determinar la cobertura de la submuestra y el n√∫mero de submuestras cubiertas determina cu√°nto contribuye el color del p√≠xel al b√∫fer de fotogramas.\nLa cantidad de puntos de muestra puede ser cualquier n√∫mero que deseemos, entre m√°s muestras se logra una mejor precisi√≥n de cobertura. Continuando con un p√≠xel que contiene 4 submuestras, para cada p√≠xel cuantas menos submuestras forman parte del tri√°ngulo, menos toma el color del tri√°ngulo. Si tuvi√©ramos que completar los colores reales de los p√≠xeles, obtendr√≠amos la siguiente imagen, donde los bordes irregulares del tri√°ngulo ahora est√°n rodeados por colores ligeramente m√°s claros que el color del borde real, lo que hace que el borde parezca suave cuando se ve desde la distancia.\nResultados y C√≥digo (Soluci√≥n) # Presione la tecla \u0026lsquo;1\u0026rsquo;, \u0026lsquo;2\u0026rsquo; o \u0026lsquo;3\u0026rsquo; para mover alguno de los puntos del triangulo y cuaalquier otra tecla para dejar de mover el punto. Discusi√≥n y Conclusiones # La t√©cnica del anti-alising es la raz√≥n por la que tenemos texto claro y formas vectoriales suaves en nuestras pantallas, esta t√©cnica mejora la precisi√≥n de la rasterizaci√≥n al incluir zonas que est√©n parcialmente cubiertas por el tri√°ngulo, dando una mayor resoluci√≥n y definici√≥n de objetos.\nEl m√©todo Multisampling es utilizando en equipos de gama media y alta ya que este corrige los jaggies en el pol√≠gono y requiere menos potencia de procesamiento por lo que es muy famoso entre los videojuegos.\nReferencias # The barycentric conspiracy. (2017, 9 abril). The Ryg Blog. https://fgiesen.wordpress.com/2013/02/06/the-barycentric-conspirac/ Anti Aliasing. Learn OpenGL. https://learnopengl.com/Advanced-OpenGL/Anti-Aliasing S. (2015, 25 enero). Rasterization: a Practical Implementation (Rasterization: a Practical Implementation). ¬© 2009‚Äì2016 Scratchapixel. https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/rasterization-practical-implementation GeeksforGeeks. (2019, 31 enero). Computer Graphics | Antialiasing. https://www.geeksforgeeks.org/computer-graphics-antialiasing/ Wikipedia. (2021). Antialiasing. Wikipedia, la enciclopedia libre. https://es.wikipedia.org/wiki/Antialiasing "},{"id":6,"href":"/showcase/docs/Talleres/Scene-Trees/Main_Spaces/","title":"Main Spaces","section":"Scene Trees","content":" Main Spaces # Introducci√≥n # El desarrollo de este taller tiene como objetivo implementar una herramienta de dibujo 3D, apoyandonos en el uso de librerias tales como p5.treegl, p5.EasyCam y ml5.js\nContexto # Teniendo como punto de partida el codigo que el profesor nos brindo en la pagina del curso e integrandolo con una libreria como ml5.js, desarrollamos una herramienta la cual permite dibujar en una interfaz 3D, adicionalmente es capaz de leer ciertos gestos con la mano, dependiendo del gesto detectado se puede cambiar ciertas configuraciones a la hora de dibujar\nResultados y C√≥digo (Soluci√≥n) # Presione la tecla \u0026lsquo;r\u0026rsquo; para grabar. Presione la tecla \u0026lsquo;c\u0026rsquo; para borrar el canvas Presione la tecla \u0026lsquo;p\u0026rsquo; para cambiar el tipo de camara Presione dos veces sobre el canvas para reiniciar la posici√≥n de la camara Con la mano haga el gesto \u0026lsquo;‚òùÔ∏è\u0026rsquo; para dibujar con una esfera Con la mano haga el gesto \u0026lsquo;‚úåÔ∏è\u0026rsquo; para dibujar con una caja Con la mano haga el gesto \u0026lsquo;üëå\u0026rsquo; para dibujar con un cono Con la mano haga el gesto \u0026lsquo;‚úä\u0026rsquo; para cambiar el color main-spaces // Goal in the 3d Brush is double, to implement: // 1. a gesture parser to deal with depth, i.e., // replace the depth slider with something really // meaningful. You may use a 3d sensor hardware // such as: https://en.wikipedia.org/wiki/Leap_Motion // or machine learning software to parse hand (or // body) gestures from a (video) / image, such as: // https://ml5js.org/ // 2. other brushes to stylize the 3d brush, taking // into account its shape and alpha channel, gesture // speed, etc. // Brush controls let depth; let brush; let easycam; let state; let escorzo; let points; let record; let handpose; let video; let hands = []; let colorIndex = 0; let colorsDefault = [\u0026#34;#00ff00\u0026#34;, \u0026#34;#bb00ff\u0026#34;, \u0026#34;#0000ff\u0026#34;, \u0026#34;#ffff00\u0026#34;]; let selectorsColor = []; let selectorFigure; let sizeX = 735 let sizeY = 600 let stateHand = \u0026#34;initial\u0026#34; //Closed, Unknow, Open, One, Two, Three function setup() { createCanvas(sizeX, sizeY, WEBGL); video = createCapture(VIDEO); video.size(sizeX/5, sizeY/5); handpose = ml5.handpose(video, modelReady); // This sets up an event that fills the global variable \u0026#34;predictions\u0026#34; // with an array every time new hand poses are detected // Hide the video element, and just show the canvas video.hide(); handpose.on(\u0026#34;hand\u0026#34;, results =\u0026gt; { hands = results; }); // easycam stuff let state = { distance: 250, // scalar center: [0, 0, 0], // vector rotation: [0, 0, 0, 1], // quaternion }; easycam = createEasyCam(); easycam.state_reset = state; // state to use on reset (double-click/tap) easycam.setState(state, 2000); // now animate to that state escorzo = true; perspective(); // brush stuff points = []; selectorFigure = createSelect(); selectorFigure.position(sizeX-80, 230); selectorFigure.option(\u0026#39;Sphere\u0026#39;); selectorFigure.option(\u0026#39;Box\u0026#39;); selectorFigure.option(\u0026#39;Cone\u0026#39;); selectorFigure.selected(\u0026#39;Sphere\u0026#39;); for (let i = 0; i\u0026lt;4 ; i++){ selectorsColor[i] = createColorPicker(colorsDefault[i]); selectorsColor[i].position(width - 70, 30+(i*50)); } // select initial brush brush = brushFun; } function modelReady() { console.log(\u0026#34;Model ready!\u0026#34;); } //Funcion que mapea una coordenada, normalizando y escalando function mapCord(cord, originMin, originMax, min, max) { return (cord-originMin)/(originMax-originMin) * (max-min) + min } function draw() { update(); background(120); push(); strokeWeight(0.8); stroke(\u0026#39;magenta\u0026#39;); grid({ dotted: false }); pop(); axes(); for (const point of points) { push(); translate(point.worldPosition); brush(point); pop(); } beginHUD(); image(video, 0, 0, sizeX/4, sizeY/4); // fill(colorSel); // noStroke(); // rect(width - 70, 20, 40, 40); noStroke(); fill(selectorsColor[colorIndex].color()); switch (selectorFigure.value()) { case \u0026#34;Sphere\u0026#34;: circle(width - 95, 35+(colorIndex*50), 20); break; case \u0026#34;Box\u0026#34;: square(width - 105, 25+(colorIndex*50), 19); break; case \u0026#34;Cone\u0026#34;: triangle(width - 105, 45+(colorIndex*50), width - 95, 25+(colorIndex*50), width - 85,45+(colorIndex*50)); break; default: break; } drawKeypoints(); endHUD(); } function checkGesture(landmarks){ let fingers = [ landmarks.indexFinger, landmarks.middleFinger, landmarks.pinky, landmarks.ringFinger ] let isOpen = true; let isClosed = true; let isOne = true; let isTwo = true; let isThree = true; for (let finger of fingers){ for(let pos=1; pos \u0026lt; finger.length ; pos++){ if(finger[pos-1][1] \u0026lt;= finger[pos][1]){ isOpen=false; break; } } } if(isOpen) return \u0026#34;Open\u0026#34; for (let finger of fingers){ if(finger[0][1] \u0026gt; finger[3][1]){ isClosed=false; break; } } if(isClosed) return \u0026#34;Closed\u0026#34; fingers = [ landmarks.middleFinger, landmarks.pinky, landmarks.ringFinger ] for (let finger of fingers){ if(finger[0][1] \u0026gt; finger[3][1]){ isOne=false; break; } } for(let pos=1; pos \u0026lt; landmarks.indexFinger.length ; pos++){ if(landmarks.indexFinger[pos-1][1] \u0026lt;= landmarks.indexFinger[pos][1]){ isOne=false; break; } } if(isOne) return \u0026#34;One\u0026#34; fingers = [ landmarks.pinky, landmarks.ringFinger ] for (let finger of fingers){ if(finger[0][1] \u0026gt; finger[3][1]){ isTwo=false; break; } } fingers = [ landmarks.indexFinger, landmarks.middleFinger, ] for (let finger of fingers){ for(let pos=1; pos \u0026lt; finger.length ; pos++){ if(finger[pos-1][1] \u0026lt;= finger[pos][1]){ isTwo=false; break; } } } if(isTwo) return \u0026#34;Two\u0026#34; if(landmarks.indexFinger[2][1] \u0026gt; landmarks.indexFinger[3][1]){ isThree=false; } fingers = [ landmarks.middleFinger, landmarks.pinky, landmarks.ringFinger ] for (let finger of fingers){ for(let pos=1; pos \u0026lt; finger.length ; pos++){ if(finger[pos-1][1] \u0026lt;= finger[pos][1]){ isThree=false; break; } } } if(isThree) return \u0026#34;Three\u0026#34; return \u0026#34;Unknown\u0026#34;; } //Cambia el color cada que se llama (Verde, Morado, Azul, Amarillo, Cian) function switchSelector(){ colorIndex=(colorIndex+1)%4; } function update() { let dx = abs(mouseX - pmouseX); let dy = abs(mouseY - pmouseY); speed = constrain((dx + dy) / (2 * (width - height)), 0, 1); let lastStateHand = stateHand; // console.log(\u0026#34;mouseX\u0026#34; + mouseX + \u0026#34;mouseX\u0026#34; + mouseY); // console.log(\u0026#34;pmouseX\u0026#34; + pmouseX + \u0026#34;pmouseY\u0026#34; + pmouseY); // console.log(\u0026#34;---------\u0026#34;); if(hands[0]?.annotations){ stateHand = checkGesture(hands[0].annotations); console.log(stateHand) if(lastStateHand != stateHand){ if(stateHand == \u0026#34;Closed\u0026#34;){ switchSelector(); } if(stateHand == \u0026#34;One\u0026#34;){ selectorFigure.selected(\u0026#39;Sphere\u0026#39;); } if(stateHand == \u0026#34;Two\u0026#34;){ selectorFigure.selected(\u0026#39;Box\u0026#39;); } if(stateHand == \u0026#34;Three\u0026#34;){ selectorFigure.selected(\u0026#39;Cone\u0026#39;); } } if (record) { points.push({ worldPosition: treeLocation([ mapCord(600-hands[0].annotations.indexFinger[3][0], 30, 600, 0, sizeX), mapCord(hands[0].annotations.indexFinger[3][1], 30, 460, 0, sizeY), mapCord(1-hands[0].annotations.indexFinger[3][2], -60, 60, 0.2, 0.8)], { from: \u0026#39;SCREEN\u0026#39;, to: \u0026#39;WORLD\u0026#39; }), color: selectorsColor[colorIndex].color(), speed: speed, figure: selectorFigure.value(), }); } }else{ stateHand=\u0026#34;Unknown\u0026#34;; } } function brushFun(point) { push(); noStroke(); // TODO parameterize sphere radius and / or // alpha channel according to gesture speed fill(point.color); switch (point.figure) { case \u0026#34;Sphere\u0026#34;: sphere(3); break; case \u0026#34;Box\u0026#34;: box(5); break; case \u0026#34;Cone\u0026#34;: cone(5); break; default: sphere(3); break; } pop(); } function keyPressed() { if (key === \u0026#39;r\u0026#39;) { record = !record; } if (key === \u0026#39;p\u0026#39;) { escorzo = !escorzo; escorzo ? perspective() : ortho(); } if (key == \u0026#39;c\u0026#39;) { points = []; } } function mouseWheel(event) { //comment to enable page scrolling return false; } // A function to draw ellipses over the detected keypoints function drawKeypoints() { for (let i = 0; i \u0026lt; hands.length; i += 1) { const hand = hands[i]; for (let j = 0; j \u0026lt; hand.landmarks.length; j += 1) { const keypoint = hand.landmarks[j]; fill(selectorsColor[colorIndex].color()); noStroke(); ellipse( mapCord(600-keypoint[0], 30, 600, 0, sizeX), mapCord(keypoint[1], 30, 460, 0, sizeY), 10, 10); } } } Discusi√≥n # La libreria ml5.js no es precisa a la hora de detectar los movimientos de la mano, la profundidad se altera con facilidad Se pueden programar mas gestos y dar una mayor cantidad de opciones de lo que puede llegar a realizar con solo gestos de la mano Con el uso de un hardware especializado como el LeapMotion se puede llegar a tener un mejor rastreo de los movimientos de las manos, lastimosamente el software del LeapMotion esta desactualizado y sin soporte, las librerias actualmente utilizan un puerto websocket por el cual recibian la informacion del LeapMotion, pero actualmente el controlador ya no crea el servidor por el cual se conecta con las librerias, dejando las libreerias desactualizadas y sin funcionamiento Conclusiones # Se pueden realizar interfaces 3D capaces de detectar gestos para dibujar, con algunas mejoras en el hardware implementado se puede mejorar en la experiencia que tiene el usuario para dibujar\nReferencias # ml5.js Handpose. https://learn.ml5js.org/#/reference/handpose "},{"id":7,"href":"/showcase/docs/Talleres/Shaders/Ejercicios/","title":"Ejercicios","section":"Shaders","content":" Procedural texturing # Introducci√≥n # El desarrollo de este taller tiene como objetivo familiarizarse con el uso de shaders\nContexto # En este ejercicio se busca implementar otras herramientas de brillo de color ( coloring brightness ), tales como el valor V de HSV, la luminosidad L de HSL y el promedio de componentes, teniendo como punto de partida el codigo brindado por el profesor en la pagina del curso.\nLos metodos implementados corresponden a las siguientes ecuaciones:\nComponent average \\[ I = avg(R, G, G) = \\frac 1 3 (R \u0026#43; G \u0026#43; B) \\] HSV value V \\[ V = max(R, G, G) = M \\] HSL lightness L \\[ V = mimd(R, G, G) = \\frac 1 2 (M \u0026#43; m) \\] Resultados y C√≥digo (Soluci√≥n) # coloring brightness let lumaShader; let img; let grey_scale; function preload() { lumaShader = readShader(\u0026#39;/showcase/sketches/texturing/brightness.frag\u0026#39;, { varyings: Tree.texcoords2 }); // image source: https://en.wikipedia.org/wiki/HSL_and_HSV#/media/File:Fire_breathing_2_Luc_Viatour.jpg img = loadImage(\u0026#39;/showcase/sketches/fire_breathing.jpg\u0026#39;); } function setup() { createCanvas(700, 500, WEBGL); noStroke(); textureMode(NORMAL); shader(lumaShader); grey_scale = createRadio(); grey_scale.option(\u0026#39;1\u0026#39;, \u0026#39;Color photograph (RGB)\u0026#39;); grey_scale.option(\u0026#39;2\u0026#39;, \u0026#39;Luma\u0026#39;); grey_scale.option(\u0026#39;3\u0026#39;, \u0026#39;Component average\u0026#39;); grey_scale.option(\u0026#39;4\u0026#39;, \u0026#39;HSV\u0026#39;); grey_scale.option(\u0026#39;5\u0026#39;, \u0026#39;HSL\u0026#39;); grey_scale.selected(\u0026#39;1\u0026#39;); grey_scale.changed(() =\u0026gt; lumaShader.setUniform(\u0026#39;grey_scale\u0026#39;, grey_scale.value())); lumaShader.setUniform(\u0026#39;texture\u0026#39;, img); lumaShader.setUniform(\u0026#39;grey_scale\u0026#39;, grey_scale.value()); } function draw() { background(0); quad(-width / 2, -height / 2, width / 2, -height / 2, width / 2, height / 2, -width / 2, height / 2); } brightness.frag precision mediump float; // uniforms are defined and sent by the sketch uniform int grey_scale; uniform sampler2D texture; // interpolated texcoord (same name and type as in vertex shader) varying vec2 texcoords2; // returns luma of given texel float luma(vec3 texel) { return 0.299 * texel.r + 0.587 * texel.g + 0.114 * texel.b; } // returns component average of given texel float average(vec3 texel) { return (texel.r + texel.g + texel.b)/3.0; } // returns HSV value of given texel float hsv(vec3 texel) { return max (max (texel.r, texel.g), texel.b); } // returns HSL lightness of given texel float hsl(vec3 texel) { return max(max(texel.r, texel.g), texel.b) / 2.0 + min(min(texel.r, texel.g), texel.b) / 2.0; } void main() { // texture2D(texture, texcoords2) samples texture at texcoords2 // and returns the normalized texel color vec4 texel = texture2D(texture, texcoords2); // gl_FragColor = grey_scale ? vec4((vec3(luma(texel.rgb))), 1.0) : texel; if(grey_scale == 1) { gl_FragColor = texel; }else if(grey_scale == 2) { gl_FragColor = vec4((vec3(luma(texel.rgb))), 1.0); }else if(grey_scale == 3) { gl_FragColor = vec4((vec3(average(texel.rgb))), 1.0); }else if(grey_scale == 4) { gl_FragColor = vec4((vec3(hsv(texel.rgb))), 1.0); }else{ gl_FragColor = vec4((vec3(hsl(texel.rgb))), 1.0); // } } "},{"id":8,"href":"/showcase/docs/Talleres/Shaders/Image-Processing/","title":"Image Processing","section":"Shaders","content":" Image Processing # Contexto # Aplicar sobre una zona el kernel seleccionado, o aplicar un kernel personalizado sobre una imagen o un video\nResultados y C√≥digo (Soluci√≥n) # Deslice el mouse sobre el canvas para aplicar el shader en la zona. En la esquina superior derecha puede ajustar el kernel. En la esquina superior derecha puede seleccionar entre la imagen y el video. imgprocess.js let image; let video; let videoCheck; let maskOption; let shaderMask; let mask = [0, -1, 0, -1, 5, -1, 0, -1, 0] let input = [9]; let button; let selectorFigure; function preload() { video = createVideo([\u0026#39;/showcase/sketches/imgprocess/dogs.webm\u0026#39;]); video.hide(); // by default video shows up in separate dom shaderMask = loadShader(\u0026#39;/showcase/sketches/imgprocess/shader.vert\u0026#39;, \u0026#39;/showcase/sketches/imgprocess/mask.frag\u0026#39;); image = loadImage(\u0026#39;/showcase/sketches/imgprocess/test.jpg\u0026#39;); // image = loadImage(\u0026#39;/showcase/sketches/imgprocess/test2.jpg\u0026#39;); // image = loadImage(\u0026#39;/showcase/sketches/imgprocess/test3.jpeg\u0026#39;); // image = loadImage(\u0026#39;/showcase/sketches/imgprocess/test4.jpg\u0026#39;); } function setup() { // shaders require WEBGL mode to work createCanvas(700, 550, WEBGL); noStroke(); textureMode(NORMAL); videoCheck = createCheckbox(\u0026#39;video\u0026#39;, false); videoCheck.style(\u0026#39;color\u0026#39;, \u0026#39;white\u0026#39;); videoCheck .changed(() =\u0026gt; { if (videoCheck.checked()) { shaderMask.setUniform(\u0026#39;texture\u0026#39;, video); video.loop(); } else { shaderMask.setUniform(\u0026#39;texture\u0026#39;, image); video.pause(); } }); videoCheck.position(640, 40); maskOption = createCheckbox(\u0026#39;options\u0026#39;, false); maskOption.position(640, 20); maskOption.style(\u0026#39;color\u0026#39;, \u0026#39;white\u0026#39;); maskOption.changed(() =\u0026gt; { if (maskOption.checked()) { for (const inp in input) { input[inp].show(); selectorFigure.show(); button.show(); } }else{ for (const inp in input) { input[inp].hide(); button.hide(); selectorFigure.hide(); } } }); shader(shaderMask); shaderMask.setUniform(\u0026#39;texture\u0026#39;, image); emitTexOffset(shaderMask, image, \u0026#39;texOffset\u0026#39;); shaderMask.setUniform(\u0026#39;radius\u0026#39;, 50*pixelDensity()); shaderMask.setUniform(\u0026#39;u_resolution\u0026#39;, [width*pixelDensity(), height*pixelDensity()]); for (let i = 0; i \u0026lt; 3; i++) { for (let j = 0; j \u0026lt; 3; j++) { input[i*3+j] = createInput(); input[i*3+j].position(200+(j*50), 200+(i*50)); input[i*3+j].style(\u0026#39;text-align:center\u0026#39;); input[i*3+j].style(\u0026#39;font-size:16px\u0026#39;); input[i*3+j].size(42,44); input[i*3+j].hide(); input[i*3+j].value(mask[i*3+j]); } } button = createButton(\u0026#39;Aplicar\u0026#39;); button.position(400, 265); button.mousePressed(apply); button.hide(); selectorFigure = createSelect(); selectorFigure.position(400, 230); selectorFigure.option(\u0026#39;Sharpen\u0026#39;); selectorFigure.option(\u0026#39;Ridge detection\u0026#39;); selectorFigure.option(\u0026#39;Blur\u0026#39;); selectorFigure.option(\u0026#39;Personalized\u0026#39;); selectorFigure.option(\u0026#39;Identity\u0026#39;); selectorFigure.selected(\u0026#39;Sharpen\u0026#39;); selectorFigure.hide(); selectorFigure.changed(() =\u0026gt; { switch(selectorFigure.value()){ case \u0026#34;Sharpen\u0026#34;: changeInputs([0, -1, 0, -1, 5, -1, 0, -1, 0]); break; case \u0026#34;Ridge detection\u0026#34;: changeInputs([-1, -1, -1, -1, 8, -1, -1, -1, -1]) break; case \u0026#34;Blur\u0026#34;: changeInputs([1/9, 1/9, 1/9, 1/9, 1/9, 1/9, 1/9, 1/9, 1/9]); break; case \u0026#34;Identity\u0026#34;: changeInputs([0, 0, 0, 0, 1, 0, 0, 0, 0]); break; case \u0026#34;Personalized\u0026#34;: apply(); break; } }); } function changeInputs(masks){ for (let i = 0; i \u0026lt; 9; i++) { input[i].value(masks[i]); } apply(); } function apply() { mask = [parseFloat(input[0].value()), parseFloat(input[1].value()), parseFloat(input[2].value()), parseFloat(input[3].value()), parseFloat(input[4].value()), parseFloat(input[5].value()), parseFloat(input[6].value()), parseFloat(input[7].value()), parseFloat(input[8].value())] } function reset() { mask = createQuadrille([[0.0625, 0.125, 0.0625], [0.125, 0.25, 0.125], [0.0625, 0.125, 0.0625]]); } function draw() { if(maskOption.checked()){ background(\u0026#39;#060621\u0026#39;); }else{ background(0); shaderMask.setUniform(\u0026#39;mask\u0026#39;, mask); shaderMask.setUniform(\u0026#39;u_mouse\u0026#39;, [mouseX*pixelDensity(), (height - mouseY)*pixelDensity()]); cover(true); quad(-width / 2, -height / 2, width / 2, -height / 2, width / 2, height / 2, -width / 2, height / 2); } } function cover(texture = false) { beginShape(); if (texture) { vertex(-width / 2, -height / 2, 0, 0, 0); vertex(width / 2, -height / 2, 0, 1, 0); vertex(width / 2, height / 2, 0, 1, 1); vertex(-width / 2, height / 2, 0, 0, 1); } else { vertex(-width / 2, -height / 2, 0); vertex(width / 2, -height / 2, 0); vertex(width / 2, height / 2, 0); vertex(-width / 2, height / 2, 0); } endShape(CLOSE); } mask.frag precision mediump float; uniform vec2 u_resolution; uniform vec2 u_mouse; uniform float radius; // we need our interpolated color varying vec4 vVertexColor; // we need our interpolated tex coord varying vec2 vTexCoord; uniform sampler2D texture; uniform vec2 texOffset; // holds the 3x3 kernel uniform float mask[9]; void main() { float pct = distance(gl_FragCoord.xy, u_mouse); if (pct \u0026gt;= radius) { gl_FragColor = texture2D(texture, vTexCoord) * vVertexColor; } else { // 1. Use offset to move along texture space. // In this case to find the texcoords of the texel neighbours. vec2 tc0 = vTexCoord + vec2(-texOffset.s, -texOffset.t); vec2 tc1 = vTexCoord + vec2( 0.0, -texOffset.t); vec2 tc2 = vTexCoord + vec2(+texOffset.s, -texOffset.t); vec2 tc3 = vTexCoord + vec2(-texOffset.s, 0.0); // origin (current fragment texcoords) vec2 tc4 = vTexCoord + vec2( 0.0, 0.0); vec2 tc5 = vTexCoord + vec2(+texOffset.s, 0.0); vec2 tc6 = vTexCoord + vec2(-texOffset.s, +texOffset.t); vec2 tc7 = vTexCoord + vec2( 0.0, +texOffset.t); vec2 tc8 = vTexCoord + vec2(+texOffset.s, +texOffset.t); // 2. Sample texel neighbours within the rgba array vec4 rgba[9]; rgba[0] = texture2D(texture, tc0); rgba[1] = texture2D(texture, tc1); rgba[2] = texture2D(texture, tc2); rgba[3] = texture2D(texture, tc3); rgba[4] = texture2D(texture, tc4); rgba[5] = texture2D(texture, tc5); rgba[6] = texture2D(texture, tc6); rgba[7] = texture2D(texture, tc7); rgba[8] = texture2D(texture, tc8); // 3. Apply convolution kernel vec4 convolution; for (int i = 0; i \u0026lt; 9; i++) { convolution += rgba[i]*mask[i]; } // 4. Set color from convolution gl_FragColor = vec4(convolution.rgb, 1.0); } } shader.vert // Precision seems mandatory in webgl precision highp float; // 1. Attributes and uniforms sent by p5.js // Vertex attributes and some uniforms are sent by // p5.js following these naming conventions: // https://github.com/processing/p5.js/blob/main/contributor_docs/webgl_mode_architecture.md // 1.1. Attributes // vertex position attribute attribute vec3 aPosition; // vertex texture coordinate attribute attribute vec2 aTexCoord; // vertex color attribute attribute vec4 aVertexColor; // 1.2. Matrix uniforms // The vertex shader should project the vertex position into clip space: // vertex_clipspace = vertex * projection * view * model (see the gl_Position below) // Details here: http://visualcomputing.github.io/Transformations // Either a perspective or an orthographic projection uniform mat4 uProjectionMatrix; // modelview = view * model uniform mat4 uModelViewMatrix; // B. varying variable names are defined by the shader programmer: // vertex color varying vec4 vVertexColor; // vertex texcoord varying vec2 vTexCoord; void main() { // copy / interpolate color vVertexColor = aVertexColor; // copy / interpolate texcoords vTexCoord = aTexCoord; // vertex projection into clipspace gl_Position = uProjectionMatrix * uModelViewMatrix * vec4(aPosition, 1.0); } Discusi√≥n # Utilizando mascaras de convolucion adecuadas se podrian a llegar a detectar objetos, sin el uso de machine learning Conclusiones # El procesamiento en tiempo real de una imagen puede ser muy util sobre todo en el area de la salud El uso de la GPU con la libreria de WEBGL permite que el procesamiento en tiempo real de una imagen o video sea fluidos Referencias # Jean Pierre Charalambos. p5.treegl.js. https://github.com/VisualComputing/p5.treegl Wikipedia. Kernel (image processing). https://en.wikipedia.org/wiki/Kernel_%28image_processing%29 "},{"id":9,"href":"/showcase/docs/Talleres/Shaders/Procedural-texturing/","title":"Procedural Texturing","section":"Shaders","content":" Texture sampling - coloring brightness # Introducci√≥n # El desarrollo de este taller tiene como objetivo familiarizarse con el uso de shaders\nContexto # En este ejercicio se busca implementar un algoritmo el cual permita crear un patron el cual pueda ser asignada como textura a una figura.\nA continuaci√≥n se muestra un patron similar al de una pared de ladrillos donde cada subregi√≥n es pintada.\nResultados y C√≥digo (Soluci√≥n) # pattern let pg; let truchetShader; let colorS; function preload() { // shader adapted from here: https://thebookofshaders.com/09/ truchetShader = readShader(\u0026#39;/showcase/sketches/texturing/pattern.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }); } function setup() { createCanvas(400, 400, WEBGL); // create frame buffer object to render the procedural texture pg = createGraphics(400, 400, WEBGL); textureMode(NORMAL); noStroke(); pg.noStroke(); pg.textureMode(NORMAL); // use truchetShader to render onto pg pg.shader(truchetShader); // emitResolution, see: // https://github.com/VisualComputing/p5.treegl#macros pg.emitResolution(truchetShader); // https://p5js.org/reference/#/p5.Shader/setUniform truchetShader.setUniform(\u0026#39;u_zoom\u0026#39;, 3); // pg clip-space quad (i.e., both x and y vertex coordinates ‚àà [-1..1]) pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); // set pg as texture texture(pg); } function draw() { background(33); orbitControl(); rotateY(millis() / 800); cone(100, 200); } function mouseMoved() { // https://p5js.org/reference/#/p5.Shader/setUniform truchetShader.setUniform(\u0026#39;u_zoom\u0026#39;, int(map(mouseX, 0, width, 1, 30))); // pg clip-space quad (i.e., both x and y vertex coordinates ‚àà [-1..1]) pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); } pattern.frag // Author @patriciogv ( patriciogonzalezvivo.com ) - 2015 #ifdef GL_ES precision mediump float; #endif uniform vec2 u_resolution; uniform float u_time; uniform bool colorSh; vec2 brickTile(vec2 _st, float _zoom){ _st *= _zoom; // Here is where the offset is happening _st.x += step(1., mod(_st.y,2.0)) * 0.5; return fract(_st); } float box(vec2 _st, vec2 _size){ _size = vec2(0.5)-_size*0.5; vec2 uv = smoothstep(_size,_size+vec2(1e-4),_st); uv *= smoothstep(_size,_size+vec2(1e-4),vec2(1.0)-_st); return uv.x*uv.y; } void main(void){ vec2 st = gl_FragCoord.xy/u_resolution.xy; vec3 color = vec3(0.0); // Apply the brick tiling st = brickTile(st,5.0); color = vec3(box(st,vec2(0.9))); color = vec3(st,0.0); gl_FragColor = vec4(color,1.0); } "},{"id":10,"href":"/showcase/docs/Talleres/Shaders/Texturing/","title":"Texturing","section":"Shaders","content":" Texturing # Introducci√≥n # El desarrollo de este taller tiene como objetivo familiarizarse con el uso de shaders\nContexto # Se desea aplicar un shader con una figura en especifico definiendo cada vertice de la figura a que posicion (u,v) del shader se debera aplicar\nResultados y C√≥digo (Soluci√≥n) # Deslice el mouse sobre el canvas para aplicar el shader en la zona. Con el Mouse Wheeler puede cambiar el tama√±o del shader aplicado. texturing.js let easycam; let uvShader; let opacity; let size; function preload() { // The projection and modelview matrices may be emitted separately // (i.e., matrices: Tree.pMatrix | Tree.mvMatrix), which actually // leads to the same gl_Position result. // Interpolate only texture coordinates (i.e., varyings: Tree.texcoords2). // see: https://github.com/VisualComputing/p5.treegl#handling uvShader = readShader(\u0026#39;../../../../sketches/texturing/uv_alpha.frag\u0026#39;, { varyings: Tree.texcoord2 }); } function setup() { createCanvas(600, 600, WEBGL); size = 2; // easycam stuff let state = { distance: 250, // scalar center: [0, 0, 0], // vector rotation: [0, 0, 0, 1], // quaternion }; easycam = createEasyCam(); easycam.state_reset = state; // state to use on reset (double-click/tap) easycam.setState(state, 2000); // now animate to that state textureMode(NORMAL); opacity = createSlider(0, 1, 0.5, 0.01); opacity.position(10, 25); opacity.style(\u0026#39;width\u0026#39;, \u0026#39;280px\u0026#39;); } function draw() { background(200); // reset shader so that the default shader is used to render the 3D scene resetShader(); // world space scene axes(); grid(); translate(0, -70); rotateY(0.5); fill(color(255, 0, 255, 125)); box(30, 50); translate(70, 70); fill(color(0, 255, 255, 125)); sphere(30, 50); // use custom shader shader(uvShader); // https://p5js.org/reference/#/p5.Shader/setUniform uvShader.setUniform(\u0026#39;opacity\u0026#39;, opacity.value()); // screen-space quad (i.e., x ‚àà [0..width] and y ‚àà [0..height]) // see: https://github.com/VisualComputing/p5.treegl#heads-up-display beginHUD(); noStroke(); beginShape(); vertex(mouseX, mouseY + (27*size), 10, 1, 1); vertex(mouseX + (25 *size), mouseY + (10*size), 10, 1, 0); vertex(mouseX + (20 *size), mouseY - (20*size), 10, 0, 1); vertex(mouseX - (20 *size), mouseY - (20*size), 10, 0, 1); vertex(mouseX - (25 *size), mouseY + (10*size), 10, 1, 0); endShape(); endHUD(); } function keyPressed() { if (key === \u0026#39;r\u0026#39;) { size = 1; } } function mouseWheel(event) { if(event.delta \u0026gt; 0 ) size += 0.1 else size -= 0.1 return false; } uv_alpha.frag precision mediump float; varying vec2 texcoords2; varying vec4 color4; // uniform is sent by the sketch uniform float opacity; void main() { gl_FragColor = vec4(0.0, texcoords2.yx, opacity); } "}]